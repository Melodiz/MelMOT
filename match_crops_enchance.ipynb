{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b13df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9f7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_properties(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    return fps, width, height\n",
    "\n",
    "def save_processed_video(output_path, processed_frames, fps, width, height):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for frame in processed_frames:\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "\n",
    "def play_video(video_path, speed=7):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    delay = int(1000 / (fps * speed))  # Delay between frames in milliseconds\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow('Tracked Video (3x speed)', frame)\n",
    "\n",
    "        if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_and_play_video(frames, detections, video_path, output_path, track_objects_func):\n",
    "    # Get video properties\n",
    "    fps, width, height = get_video_properties(video_path)\n",
    "\n",
    "    # Perform tracking\n",
    "    all_tracks, processed_frames = track_objects_func(frames, detections)\n",
    "\n",
    "    # Save processed video\n",
    "    save_processed_video(output_path, processed_frames, fps, width, height)\n",
    "\n",
    "    print(f\"Video processing complete. Output saved as {output_path}\")\n",
    "\n",
    "    # Play the resulting video\n",
    "    print(\"Playing the resulting video at 7x speed. Press 'q' to quit.\")\n",
    "    play_video(output_path, speed=3)\n",
    "\n",
    "def get_frame(video_path, frame_number):\n",
    "    \"\"\"\n",
    "    Get a full frame from a video\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the video file\n",
    "        frame_number (int): Frame number to extract\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Frame image or None if failed\n",
    "    \"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return None\n",
    "        \n",
    "    video.set(1, frame_number)\n",
    "    ret, frame = video.read()\n",
    "    video.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read frame {frame_number} from {video_path}\")\n",
    "        return None\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    return frame\n",
    "def get_crop(video_path, bbox, frame_number):\n",
    "    # Read the frame\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    video.set(1, frame_number)\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get the bounding box coordinates\n",
    "    left, top, right, bottom = map(int, bbox)\n",
    "    \n",
    "    # Ensure coordinates are within frame boundaries\n",
    "    height, width = frame.shape[:2]\n",
    "    left = max(0, min(left, width-1))\n",
    "    right = max(left+1, min(right, width))\n",
    "    top = max(0, min(top, height-1))\n",
    "    bottom = max(top+1, min(bottom, height))\n",
    "    \n",
    "    try:\n",
    "        crop = frame[top:bottom, left:right]\n",
    "        return crop\n",
    "    except Exception as e:\n",
    "        print(f\"Error cropping image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1e5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "track1 = {'frame': 262, 'bbox': [466.439801847985, 452.6626321718736, 788.9695855184984, 718.11660942189], 'confidence': 0.9248402118682861, 'lower_bbox_point': [627, 718], 'timestamp': 262, 'real_coordinates': [1.0991828441619873, 4.47562837600708]}\n",
    "track2 = {'frame': 318, 'bbox': [74.98400845175811, 178.01272629795963, 141.43165164620422, 321.97255564997886], 'confidence': 0.8068757653236389, 'lower_bbox_point': [108, 321], 'timestamp': 262, 'real_coordinates': [1.4676921367645264, 4.4983367919921875]} \n",
    "\n",
    "video_path1 = 'videos/1.mp4'\n",
    "video_path2 = 'videos/2.mp4 '\n",
    "query_id=26; base_id=10; save_silent=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e85936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video videos/2.mp4 \n",
      "Error: Could not read one or both frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"videos/2.mp4 \"\n"
     ]
    }
   ],
   "source": [
    "plot_two_crops(track1, track2, video_path1, video_path2, query_id, base_id, save_silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc26375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_two_crops(track1, track2, video_path1, video_path2, query_id=None, base_id=None, save_silent=False):\n",
    "    \"\"\"\n",
    "    Plot two full frames side by side with bounding boxes and annotations\n",
    "    \n",
    "    Args:\n",
    "        track1: Track data for the first image\n",
    "        track2: Track data for the second image\n",
    "        video_path1: Path to the first video\n",
    "        video_path2: Path to the second video\n",
    "        query_id: Optional ID for the query track (first image)\n",
    "        base_id: Optional ID for the base track (second image)\n",
    "    \"\"\"\n",
    "    # Get full frames instead of crops\n",
    "    frame1 = get_frame(video_path1, track1['frame'])\n",
    "    frame2 = get_frame(video_path2, track2['frame'])\n",
    "    \n",
    "    if frame1 is None or frame2 is None:\n",
    "        print(\"Error: Could not read one or both frames\")\n",
    "        return\n",
    "    \n",
    "    # Extract video names from paths (just the filename)\n",
    "    video1_name = video_path1.split('/')[-1]\n",
    "    video2_name = video_path2.split('/')[-1]\n",
    "    \n",
    "    # Format coordinates and timestamps nicely\n",
    "    coords1 = f\"({track1['real_coordinates'][0]:.2f}, {track1['real_coordinates'][1]:.2f})\"\n",
    "    coords2 = f\"({track2['real_coordinates'][0]:.2f}, {track2['real_coordinates'][1]:.2f})\"\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Annotate and plot first frame\n",
    "    frame1_rgb = frame1.copy()  # Make a copy to avoid modifying the original\n",
    "    frame1_bgr = cv2.cvtColor(frame1_rgb, cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV functions\n",
    "    \n",
    "    # Draw bounding box on first frame\n",
    "    bbox1 = track1['bbox']\n",
    "    x1, y1, x2, y2 = map(int, bbox1)\n",
    "    \n",
    "    # Generate a unique color for this track ID\n",
    "    track_id1 = query_id if query_id is not None else 1\n",
    "    color_hash1 = hash(str(track_id1)) % 0xFFFFFF\n",
    "    color1 = ((color_hash1 >> 16) & 0xFF, (color_hash1 >> 8) & 0xFF, color_hash1 & 0xFF)  # RGB format\n",
    "    color1_bgr = (color1[2], color1[1], color1[0])  # BGR format for OpenCV\n",
    "    \n",
    "    # Draw rectangle\n",
    "    cv2.rectangle(frame1_bgr, (x1, y1), (x2, y2), color=color1_bgr, thickness=2)\n",
    "    \n",
    "    # Create label with ID\n",
    "    label1 = f\"ID: {track_id1}\"\n",
    "    \n",
    "    # Calculate text size for better positioning\n",
    "    text_size1 = cv2.getTextSize(label1, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "    \n",
    "    # Draw background rectangle for text\n",
    "    cv2.rectangle(\n",
    "        frame1_bgr,\n",
    "        (x1, y1 - text_size1[1] - 10),\n",
    "        (x1 + text_size1[0] + 10, y1),\n",
    "        color1_bgr,\n",
    "        -1  # Fill the rectangle\n",
    "    )\n",
    "    \n",
    "    # Draw ID text with white color for better visibility\n",
    "    cv2.putText(\n",
    "        frame1_bgr,\n",
    "        label1,\n",
    "        (x1 + 5, y1 - 5),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.6,\n",
    "        (255, 255, 255),  # White text\n",
    "        2,\n",
    "        lineType=cv2.LINE_AA\n",
    "    )\n",
    "    \n",
    "    # Convert back to RGB for matplotlib\n",
    "    frame1_annotated = cv2.cvtColor(frame1_bgr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Plot the annotated frame\n",
    "    axs[0].imshow(frame1_annotated)\n",
    "    title1 = f\"{video1_name}\"\n",
    "    if query_id is not None:\n",
    "        title1 += f\" - ID: {query_id}\"\n",
    "    axs[0].set_title(title1, fontsize=12)\n",
    "    \n",
    "    # Add annotations as text below the image\n",
    "    axs[0].text(0.5, -0.05, f\"Frame: {track1['frame']}\", \n",
    "                transform=axs[0].transAxes, ha='center', fontsize=10)\n",
    "    axs[0].text(0.5, -0.10, f\"Coordinates: {coords1}\", \n",
    "                transform=axs[0].transAxes, ha='center', fontsize=10)\n",
    "    axs[0].text(0.5, -0.15, f\"Time: {track1['timestamp']:.2f}s\", \n",
    "                transform=axs[0].transAxes, ha='center', fontsize=10)\n",
    "    \n",
    "    # Annotate and plot second frame\n",
    "    frame2_rgb = frame2.copy()  # Make a copy to avoid modifying the original\n",
    "    frame2_bgr = cv2.cvtColor(frame2_rgb, cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV functions\n",
    "    \n",
    "    # Draw bounding box on second frame\n",
    "    bbox2 = track2['bbox']\n",
    "    x1, y1, x2, y2 = map(int, bbox2)\n",
    "    \n",
    "    # Generate a unique color for this track ID\n",
    "    track_id2 = base_id if base_id is not None else 2\n",
    "    color_hash2 = hash(str(track_id2)) % 0xFFFFFF\n",
    "    color2 = ((color_hash2 >> 16) & 0xFF, (color_hash2 >> 8) & 0xFF, color_hash2 & 0xFF)  # RGB format\n",
    "    color2_bgr = (color2[2], color2[1], color2[0])  # BGR format for OpenCV\n",
    "    \n",
    "    # Draw rectangle\n",
    "    cv2.rectangle(frame2_bgr, (x1, y1), (x2, y2), color=color2_bgr, thickness=2)\n",
    "    \n",
    "    # Create label with ID\n",
    "    label2 = f\"ID: {track_id2}\"\n",
    "    \n",
    "    # Calculate text size for better positioning\n",
    "    text_size2 = cv2.getTextSize(label2, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "    \n",
    "    # Draw background rectangle for text\n",
    "    cv2.rectangle(\n",
    "        frame2_bgr,\n",
    "        (x1, y1 - text_size2[1] - 10),\n",
    "        (x1 + text_size2[0] + 10, y1),\n",
    "        color2_bgr,\n",
    "        -1  # Fill the rectangle\n",
    "    )\n",
    "    \n",
    "    # Draw ID text with white color for better visibility\n",
    "    cv2.putText(\n",
    "        frame2_bgr,\n",
    "        label2,\n",
    "        (x1 + 5, y1 - 5),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.6,\n",
    "        (255, 255, 255),  # White text\n",
    "        2,\n",
    "        lineType=cv2.LINE_AA\n",
    "    )\n",
    "    \n",
    "    # Convert back to RGB for matplotlib\n",
    "    frame2_annotated = cv2.cvtColor(frame2_bgr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Plot the annotated frame\n",
    "    axs[1].imshow(frame2_annotated)\n",
    "    title2 = f\"{video2_name}\"\n",
    "    if base_id is not None:\n",
    "        title2 += f\" - ID: {base_id}\"\n",
    "    axs[1].set_title(title2, fontsize=12)\n",
    "    \n",
    "    # Add annotations as text below the image\n",
    "    axs[1].text(0.5, -0.05, f\"Frame: {track2['frame']}\", \n",
    "                transform=axs[1].transAxes, ha='center', fontsize=10)\n",
    "    axs[1].text(0.5, -0.10, f\"Coordinates: {coords2}\", \n",
    "                transform=axs[1].transAxes, ha='center', fontsize=10)\n",
    "    axs[1].text(0.5, -0.15, f\"Time: {track2['timestamp']:.2f}s\", \n",
    "                transform=axs[1].transAxes, ha='center', fontsize=10)\n",
    "    \n",
    "    # Remove axis ticks for cleaner visualization\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Adjust layout to make room for the text\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    \n",
    "    # Check if we should save silently or show the plot\n",
    "    if save_silent:\n",
    "        # Create the reid directory if it doesn't exist\n",
    "        import os\n",
    "        os.makedirs(\"reid\", exist_ok=True)\n",
    "        \n",
    "        # Save the figure to a file\n",
    "        save_path = f\"reid/{query_id}-{base_id}.jpg\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "        print(f\"Saved match visualization to {save_path}\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6c751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
